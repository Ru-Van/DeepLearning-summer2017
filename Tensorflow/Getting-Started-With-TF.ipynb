{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started With TensorFlow\n",
    "\n",
    "- [From Tensorflow tutorial page](https://www.tensorflow.org/get_started/get_started)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps: Recall that in the lecture, the 5 steps for running programs in tensorflow are:\n",
    "1. Create Tensors (aka variables) that are not yet executed or evaluated.\n",
    "2. Write operations between those tensors (the so-called computational graph)\n",
    "3. Initialize your tensors\n",
    "4. Create a Session\n",
    "5. Run the Session. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors:\n",
    "- central unit of data in Tensorflow\n",
    "- a tensor consists of a set of primitive values shaped into an ** array of number of dimensions. ** (Recall when we are doing image reduction, the size is (64,64,3)\n",
    "- a tensor's ** rank ** is its number of dimensions.'\n",
    "\n",
    "```python\n",
    "3 #a rank 0 tensor; this is a scalar with shape []\n",
    "[1.,2.,3.] # a rank 1 tensor, this is a vector with shape [3]\n",
    "[[1.,2.,3.],[4.,5.,6.]] #a rank 2 tensor, a matrix with shape [2,3]\n",
    "[[[1.,2.,3.],[4.,5.,6.]]] # a rank 3 tensor with shape [2,1,3]\n",
    "```\n",
    "\n",
    "\n",
    "## Operations and Computational Graphs\n",
    "\n",
    "- Two discrete sections:\n",
    "    - **Build** the computational graph\n",
    "    - **Run** the computational graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_2:0\", shape=(), dtype=float32) Tensor(\"Const_3:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "node1 = tf.constant(3.0, dtype = tf.float32)\n",
    "node2 = tf.constant(4.0,) # implicitly dtype is float32\n",
    "print(node1, node2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will not print 3.0 and 4.0 as constants as we would expect, but instead when evaluated, would produce 3.0 and 4.0. To actually evaluate the nodes, **WE MUST RUN THE COMPUTATIONAL GRAPH WITH A SESION.**\n",
    "\n",
    "There are two ways to create a session that we learned in Deep Learning\n",
    "1. Method 1\n",
    "    ```python\n",
    "    sess = tf.Session() # create the instance\n",
    "    result = sess.run(..., feed_dict = {...}) # if you have any placeholder that you need to feed\n",
    "    sess.close() #close the session.\n",
    "    ```\n",
    "2. Method2\n",
    "    ```python\n",
    "    with tf.Session() as sess: #safer way to run session\n",
    "        result = sess.run(...,feed_dict = {...})\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.0, 4.0]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print(sess.run([node1, node2]))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run this, you have to uncomment the line above\n",
    "\n",
    "#with tf.Session() as sess:\n",
    "#    print(sess.run([node1,node2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can further build more complicated computations by combining Tensor nodes with operations(addition, multiplication, etc). ** Operations are also nodes in Tensorflow!** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node3: Tensor(\"Add_2:0\", shape=(), dtype=float32)\n",
      "sess.run(node3): 7.0\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "node3 = tf.add(node1,node2)\n",
    "print(\"node3:\",node3)\n",
    "print(\"sess.run(node3):\",sess.run(node3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A graph can further be parameterized to accept external inputs, known as ** placeholders**. A placeholder is a promise to provide a value later. (Similar to a parameter in a function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5\n",
      "7.5\n",
      "[ 3.  7.]\n",
      "[ 3.  7.]\n"
     ]
    }
   ],
   "source": [
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "add_node = a + b\n",
    "# alternatively\n",
    "adder_node = tf.add(a,b)\n",
    "#because we have already created a sess so we could just run it directly\n",
    "print(sess.run(add_node,feed_dict = {a:3,b:4.5}))\n",
    "print(sess.run(adder_node,{a:3,b:4.5})) # the keyword \"feed_dict\" is optional\"\n",
    "print(sess.run(add_node,feed_dict = {a:[1,3], b: [2,4]}))\n",
    "print(sess.run(adder_node,{a:[1,3], b: [2,4]})) #these should produce the same result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.5\n"
     ]
    }
   ],
   "source": [
    "# To make the computational graph more complex, we could do:\n",
    "add_and_triple = adder_node * 3\n",
    "print(sess.run(add_and_triple, {a:3, b:4.5}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In Machine Learning, we often need a model that can take arbitrary inputs to make the model trainable. ** Variables ** allow us to add trainable parameters to a graph.They are constructed with ** a type and initial value **\n",
    "\n",
    "- We see earlier that we use *tf.constant*, and their value can never change. By contrast, Variables are not initialized when you call *tf.Variable *. To initialize all the variables in a tensorflow program, you need to explicitly call a special operation as follow:\n",
    "```python\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "```\n",
    "\n",
    "- **init** is a handle to the TensorFlow sub-graph that initializes all the global variables. Until we call sess.run, the variables are uninitialized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.30000001  0.60000002  0.90000004]\n"
     ]
    }
   ],
   "source": [
    "W = tf.Variable([.3],dtype = tf.float32)\n",
    "b = tf.Variable([-.3], dtype = tf.float32)\n",
    "x = tf.placeholder(tf.float32)\n",
    "linear_model = W * x + b\n",
    "\n",
    "# initialize all variables\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "print(sess.run(linear_model, {x:[1,2,3,4]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have created a linear model, but we don't know how good it is. (i.e. we have the yhat, but we need the y to know how far apart is yhat from y). \n",
    "Let's use the ** standard loss model for linear regression**, which sums the squares of the deltas between the current model and the provided data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.66\n"
     ]
    }
   ],
   "source": [
    "y = tf.placeholder(tf.float32)\n",
    "squared_deltas = tf.square(linear_model - y ) # (yhat - y) ^2\n",
    "loss = tf.reduce_sum(squared_deltas)\n",
    "print(sess.run(loss,{x:[1,2,3,4], y :[0, -1, -2, -3]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# we could reassign the value of W and b y using tf.assign for any Variable\n",
    "fixW = tf.assign(W,[-1])\n",
    "fixb = tf.assign(b, [1.])\n",
    "sess.run([fixW, fixb])\n",
    "print(sess.run(loss, {x:[1,2,3,4], y:[0, -1,-2,-3]}))\n",
    "# here the cost function reach 0 because we manually change the w and b, \n",
    "# but in ml, you would train the model to find that perfect w and b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent - ML Optimization Method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-0.9999969], dtype=float32), array([ 0.99999082], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.01) #0.01 is the learning rate alpha, its the hyperparameter\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "sess.run(init) # this reset values to incorrect default\n",
    "for i in range(1000): #number of iterations\n",
    "    sess.run(train,{x:[1,2,3,4], y:[0, -1,-2,-3]})\n",
    "print(sess.run([W,b]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Notice that the number is very close to -1 and 1 but not really -1 and 1. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.estimator\n",
    "\n",
    "- tf.estimator is a higher level Tensorflow library that simplifies the mechanics of ml, that includes:\n",
    "    - running training loops\n",
    "    - running evaluation loops\n",
    "    - managing data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpao9qdbrj\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_steps': None, '_tf_random_seed': 1, '_model_dir': '/tmp/tmpao9qdbrj', '_log_step_count_steps': 100, '_session_config': None, '_save_summary_steps': 100, '_keep_checkpoint_every_n_hours': 10000, '_keep_checkpoint_max': 5, '_save_checkpoints_secs': 600}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpao9qdbrj/model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 23.0\n",
      "INFO:tensorflow:global_step/sec: 1942.01\n",
      "INFO:tensorflow:step = 101, loss = 0.277967 (0.053 sec)\n",
      "INFO:tensorflow:global_step/sec: 2209\n",
      "INFO:tensorflow:step = 201, loss = 0.0590458 (0.045 sec)\n",
      "INFO:tensorflow:global_step/sec: 2205.22\n",
      "INFO:tensorflow:step = 301, loss = 0.0223003 (0.045 sec)\n",
      "INFO:tensorflow:global_step/sec: 1894.98\n",
      "INFO:tensorflow:step = 401, loss = 0.00873921 (0.053 sec)\n",
      "INFO:tensorflow:global_step/sec: 2197.06\n",
      "INFO:tensorflow:step = 501, loss = 0.0025899 (0.046 sec)\n",
      "INFO:tensorflow:global_step/sec: 2127.04\n",
      "INFO:tensorflow:step = 601, loss = 0.00032714 (0.047 sec)\n",
      "INFO:tensorflow:global_step/sec: 2095.02\n",
      "INFO:tensorflow:step = 701, loss = 5.14576e-05 (0.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 1952.31\n",
      "INFO:tensorflow:step = 801, loss = 3.70014e-05 (0.050 sec)\n",
      "INFO:tensorflow:global_step/sec: 2465.85\n",
      "INFO:tensorflow:step = 901, loss = 1.04975e-05 (0.041 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmpao9qdbrj/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2.22196e-06.\n",
      "INFO:tensorflow:Starting evaluation at 2017-08-27-23:20:20\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpao9qdbrj/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-08-27-23:20:20\n",
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 6.38136e-07, global_step = 1000, loss = 2.55254e-06\n",
      "INFO:tensorflow:Starting evaluation at 2017-08-27-23:20:20\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpao9qdbrj/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-08-27-23:20:21\n",
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 0.00260665, global_step = 1000, loss = 0.0104266\n",
      "train metrics: {'average_loss': 6.3813616e-07, 'loss': 2.5525446e-06, 'global_step': 1000}\n",
      "eval metrics: {'average_loss': 0.0026066478, 'loss': 0.010426591, 'global_step': 1000}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#declares list of featuress. We only have one numeric feature here. But there are many\n",
    "# other types of columns that are more complicated and useful\n",
    "feature_columns = [tf.feature_column.numeric_column(\"x\", shape=[1])]\n",
    "\n",
    "estimator = tf.estimator.LinearRegressor(feature_columns=feature_columns)\n",
    "# TensorFlow provides many helper methods to read and set up data sets.\n",
    "# Here we use two data sets: one for training and one for evaluation\n",
    "# We have to tell the function how many batches\n",
    "# of data (num_epochs) we want and how big each batch should be.\n",
    "x_train = np.array([1., 2., 3., 4.])\n",
    "y_train = np.array([0., -1., -2., -3.])\n",
    "x_eval = np.array([2., 5., 8., 1.])\n",
    "y_eval = np.array([-1.01, -4.1, -7, 0.])\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=4, num_epochs=None, shuffle=True)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_eval}, y_eval, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "\n",
    "# We can invoke 1000 training steps by invoking the  method and passing the\n",
    "# training data set.\n",
    "estimator.train(input_fn=input_fn, steps=1000)\n",
    "\n",
    "# Here we evaluate how well our model did.\n",
    "train_metrics = estimator.evaluate(input_fn=train_input_fn)\n",
    "eval_metrics = estimator.evaluate(input_fn=eval_input_fn)\n",
    "print(\"train metrics: %r\"% train_metrics)\n",
    "print(\"eval metrics: %r\"% eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
